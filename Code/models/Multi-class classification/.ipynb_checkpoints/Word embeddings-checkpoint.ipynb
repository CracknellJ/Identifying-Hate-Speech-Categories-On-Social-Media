{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf -> w2v -> gloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, plot_confusion_matrix\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "#specific to this notebook\n",
    "import spacy\n",
    "#!python -m spacy download en_core_web_md\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load() \n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>Hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.969655e+17</td>\n",
       "      <td>i just found the perfect rental why cant my le...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>['found', 'perfect', 'rental', 'cant', 'lease'...</td>\n",
       "      <td>['found', 'perfect', 'rental', 'cant', 'lease'...</td>\n",
       "      <td>['i_NN', 'just_RB', 'found_VBD', 'the_DT', 'pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.758918e+17</td>\n",
       "      <td>every time they discover anything its either ...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>['every', 'time', 'discover', 'anything', 'eit...</td>\n",
       "      <td>['every', 'time', 'discover', 'anything', 'eit...</td>\n",
       "      <td>['every_DT', 'time_NN', 'they_PRP', 'discover_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.952595e+17</td>\n",
       "      <td>ok time to write code bbl\\n\\nmaking a new thing</td>\n",
       "      <td>Neither</td>\n",
       "      <td>['ok', 'time', 'write', 'code', 'bbl', 'making...</td>\n",
       "      <td>['ok', 'time', 'write', 'code', 'bbl', 'making...</td>\n",
       "      <td>['ok_JJ', 'time_NN', 'to_TO', 'write_VB', 'cod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.723449e+17</td>\n",
       "      <td>refined dessert not mkr</td>\n",
       "      <td>Neither</td>\n",
       "      <td>['refined', 'dessert', 'mkr']</td>\n",
       "      <td>['refined', 'dessert', 'mkr']</td>\n",
       "      <td>['refined_VBN', 'dessert_NN', 'not_RB', 'mkr_VB']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.681320e+17</td>\n",
       "      <td>one of the best things anyone can do to impr...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>['one', 'best', 'things', 'anyone', 'improve',...</td>\n",
       "      <td>['one', 'best', 'thing', 'anyone', 'improve', ...</td>\n",
       "      <td>['one_CD', 'of_IN', 'the_DT', 'best_JJS', 'thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text Annotation  \\\n",
       "0  5.969655e+17  i just found the perfect rental why cant my le...    Neither   \n",
       "1  5.758918e+17   every time they discover anything its either ...    Neither   \n",
       "2  5.952595e+17    ok time to write code bbl\\n\\nmaking a new thing    Neither   \n",
       "3  5.723449e+17                            refined dessert not mkr    Neither   \n",
       "4  5.681320e+17    one of the best things anyone can do to impr...    Neither   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  ['found', 'perfect', 'rental', 'cant', 'lease'...   \n",
       "1  ['every', 'time', 'discover', 'anything', 'eit...   \n",
       "2  ['ok', 'time', 'write', 'code', 'bbl', 'making...   \n",
       "3                      ['refined', 'dessert', 'mkr']   \n",
       "4  ['one', 'best', 'things', 'anyone', 'improve',...   \n",
       "\n",
       "                                          text_lemma  \\\n",
       "0  ['found', 'perfect', 'rental', 'cant', 'lease'...   \n",
       "1  ['every', 'time', 'discover', 'anything', 'eit...   \n",
       "2  ['ok', 'time', 'write', 'code', 'bbl', 'making...   \n",
       "3                      ['refined', 'dessert', 'mkr']   \n",
       "4  ['one', 'best', 'thing', 'anyone', 'improve', ...   \n",
       "\n",
       "                                            pos_tags  Hate  \n",
       "0  ['i_NN', 'just_RB', 'found_VBD', 'the_DT', 'pe...     0  \n",
       "1  ['every_DT', 'time_NN', 'they_PRP', 'discover_...     0  \n",
       "2  ['ok_JJ', 'time_NN', 'to_TO', 'write_VB', 'cod...     0  \n",
       "3  ['refined_VBN', 'dessert_NN', 'not_RB', 'mkr_VB']     0  \n",
       "4  ['one_CD', 'of_IN', 'the_DT', 'best_JJS', 'thi...     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load in data and split for train and test sets\n",
    "df = pd.read_csv(r'C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\clean_dataset.csv')\n",
    "#df = pd.read_csv(r'C:\\Users\\Jack\\Desktop\\proj\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\clean_dataset.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text_lemma'], df['Annotation'], test_size=0.25, random_state=12)\n",
    "                                                       \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create TFIDF matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_train = tfidf.fit_transform(X_train)\n",
    "tfidf_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=rbf, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=sigmoid, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear, score=0.584, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear, score=0.557, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear, score=0.644, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear, score=0.602, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=linear, score=0.638, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=auto, kernel=poly, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf, score=0.325, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf, score=0.345, total=   1.1s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf, score=0.318, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf, score=0.320, total=   1.1s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=rbf, score=0.319, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid, score=0.294, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid, score=0.292, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid, score=0.267, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid, score=0.267, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=sigmoid, score=0.277, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear, score=0.584, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear, score=0.557, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear, score=0.644, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear, score=0.602, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=linear, score=0.638, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly, score=0.294, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly, score=0.295, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly, score=0.270, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly, score=0.273, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.1, kernel=poly, score=0.277, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf, score=0.267, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf, score=0.264, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf, score=0.260, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf, score=0.250, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=rbf, score=0.243, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear, score=0.584, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear, score=0.557, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear, score=0.644, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear, score=0.602, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=linear, score=0.638, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly, score=0.228, total=   0.7s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=1, gamma=0.01, kernel=poly, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=rbf, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=sigmoid, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear, score=0.584, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear, score=0.557, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear, score=0.644, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear, score=0.602, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=linear, score=0.638, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly, score=0.228, total=   0.5s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=auto, kernel=poly, score=0.228, total=   0.4s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.325, total=   1.1s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.345, total=   1.1s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.318, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.320, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=rbf, score=0.319, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid, score=0.294, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid, score=0.292, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid, score=0.267, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid, score=0.267, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=sigmoid, score=0.277, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear, score=0.584, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear, score=0.557, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear, score=0.644, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear, score=0.602, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=linear, score=0.638, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly, score=0.228, total=   1.0s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly, score=0.228, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly, score=0.228, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly, score=0.228, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.1, kernel=poly, score=0.228, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.267, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.264, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.260, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.250, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=rbf, score=0.243, total=   0.9s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.8s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=sigmoid \n",
      "[CV]  C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=sigmoid, score=0.228, total=   0.7s\n",
      "[CV] C=1, class_weight=None, coef0=0.1, degree=3, gamma=0.01, kernel=sigmoid \n"
     ]
    }
   ],
   "source": [
    "SVM_default = svm.SVC(C=1.0, kernel='rbf', gamma='scale', shrinking=True,\n",
    "                      class_weight=None, random_state=12)\n",
    "\n",
    "# dictionary containing the parameters which will be used for grid search\n",
    "grid_search_params={'C': [1, 10, 30],  \n",
    "              'gamma': ['auto', 0.1, 0.01], \n",
    "              'kernel': ['rbf', 'sigmoid', 'linear', 'poly'],\n",
    "              'coef0': [0.1, 1, 3],\n",
    "              'degree': [1, 3, 5],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "\n",
    "# grid search with f1 being the performance metric\n",
    "SVM_grid = GridSearchCV(SVM_default, grid_search_params, cv=5, scoring='f1_macro', verbose=3)\n",
    "SVM_grid.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "print(\"training...\")\n",
    "SVM_grid.best_estimator_.fit(tfidf_train, y_train)\n",
    "print(\"complete.\")\n",
    "# use classifier to predict on test set\n",
    "print(\"predicting...\")\n",
    "SVM_test_preds = SVM_grid.best_estimator_.predict(tfidf_test)\n",
    "print(\"complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_metrics = {}\n",
    "SVM_default_precision = precision_score(y_test, SVM_test_preds)\n",
    "SVM_default_recall = recall_score(y_test, SVM_test_preds)\n",
    "SVM_default_macro_f1_score = f1_score(y_test, SVM_test_preds, average='macro')\n",
    "\n",
    "#model evaluation\n",
    "print('Model evaluation metrics')\n",
    "print('Precision: {:.3}'.format(SVM_default_precision))\n",
    "print('Recall: {:.3}'.format(SVM_default_recall))\n",
    "print('Macro F1 Score: {:.3}'.format(SVM_default_macro_f1_score))\n",
    "\n",
    "TFIDF_metrics['Default SVM'] = {'precision': SVM_default_precision, 'recall': SVM_default_recall, \n",
    "                              'macro_f1': SVM_default_macro_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(SVM_grid.best_estimator_, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_grid_LR = LogisticRegression(penalty='l2', dual=False, C=1, class_weight=None, \n",
    "                                solver='lbfgs', random_state=12)\n",
    "\n",
    "# dictionary containing the parameters which will be used for grid search\n",
    "grid_search_params={'penalty': ['l1', 'l2', 'elasticnet'],  \n",
    "              'dual': [True, False], \n",
    "              'C': [1, 10, 30],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'sag', 'saga', 'liblinear']}\n",
    "\n",
    "# grid search with f1 being the performance metric\n",
    "grid_LR = GridSearchCV(default_grid_LR, grid_search_params, cv=5, scoring='f1_macro', verbose=3)\n",
    "grid_LR.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "print(\"training...\")\n",
    "grid_LR.best_estimator_.fit(tfidf_train, y_train)\n",
    "print(\"complete.\")\n",
    "# use classifier to predict on test set\n",
    "print(\"predicting...\")\n",
    "LR_test_preds = grid_LR.best_estimator_.predict(tfidf_test)\n",
    "print(\"complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_LR_precision = precision_score(y_test, LR_test_preds)\n",
    "grid_LR_recall = recall_score(y_test, LR_test_preds)\n",
    "grid_LR_macro_f1_score = f1_score(y_test, LR_test_preds, average='macro')\n",
    "\n",
    "#model evaluation\n",
    "print('Model evaluation metrics')\n",
    "print('Precision: {:.3}'.format(grid_LR_precision))\n",
    "print('Recall: {:.3}'.format(grid_LR_recall))\n",
    "print('Macro F1 Score: {:.3}'.format(grid_LR_macro_f1_score))\n",
    "\n",
    "TFIDF_metrics['Grid LR'] = {'precision': grid_LR_precision, 'recall': grid_LR_recall, \n",
    "                            'macro_f1': grid_LR_macro_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_LR, tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_NB = GaussianNB()\n",
    "\n",
    "grid_search_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "grid_NB = GridSearchCV(grid_NB, grid_search_params, cv=5, scoring='f1_macro', verbose=3)\n",
    "\n",
    "grid_NB.fit(tfidf_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "print(\"training...\")\n",
    "grid_NB.best_estimator_.fit(tfidf_train.toarray(), y_train)\n",
    "print(\"complete.\")\n",
    "# use classifier to predict on test set\n",
    "print(\"predicting...\")\n",
    "NB_test_preds = grid_NB.best_estimator_.predict(tfidf_test.toarray())\n",
    "print(\"complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_NB_precision = precision_score(y_test, NB_test_preds)\n",
    "grid_NB_recall = recall_score(y_test, NB_test_preds)\n",
    "grid_NB_macro_f1_score = f1_score(y_test, NB_test_preds, average='macro')\n",
    "\n",
    "#model evaluation\n",
    "print('Model evaluation metrics')\n",
    "print('Precision: {:.3}'.format(grid_NB_precision))\n",
    "print('Recall: {:.3}'.format(grid_NB_recall))\n",
    "print('Macro F1 Score: {:.3}'.format(grid_NB_macro_f1_score))\n",
    "\n",
    "TFIDF_metrics['Grid NB'] = {'precision': grid_NB_precision, 'recall': grid_NB_recall, \n",
    "                            'macro_f1': grid_NB_macro_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_NB, tfidf_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare parameters\n",
    "TFIDF_results = pd.DataFrame.from_dict(TFIDF_metrics, orient='index')\n",
    "#TFIDF_results.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Results\\TFIDF_results\",\n",
    "               #index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column of word vectors\n",
    "def get_vec(x):\n",
    "  doc = nlp(x)\n",
    "  return doc.vector\n",
    "\n",
    "df['Vector'] = df['text'].apply(lambda x: get_vec(x))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(df['Vector'], df['Annotation'], test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_default = svm.SVC(C=1.0, kernel='rbf', gamma='scale', shrinking=True,\n",
    "                      class_weight=None, random_state=12)\n",
    "\n",
    "# dictionary containing the parameters which will be used for grid search\n",
    "grid_search_params={'C': [1, 10, 30],  \n",
    "              'gamma': ['auto', 0.1, 0.01], \n",
    "              'kernel': ['rbf', 'sigmoid', 'linear', 'poly'],\n",
    "              'coef0': [0.1, 1, 3],\n",
    "              'degree': [1, 3, 5],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "\n",
    "# grid search with f1 being the performance metric\n",
    "SVM_grid = GridSearchCV(SVM_default, grid_search_params, cv=5, scoring='f1_macro', verbose=3)\n",
    "SVM_grid.fit(X_train_w2v, y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_w2v = X_train_w2v.to_numpy()\n",
    "# X_train_w2v = X_train_w2v.reshape(-1,1)\n",
    "# X_train_w2v = np.concatenate(np.concatenate(X_train_w2v,axis = 0),axis = 0).reshape(-1,300)\n",
    "\n",
    "# X_test_w2v = X_test_w2v.to_numpy()\n",
    "# X_test_w2v = X_test_w2v.reshape(-1,1)\n",
    "# X_test_w2v = np.concatenate(np.concatenate(X_test_w2v,axis = 0),axis = 0).reshape(-1,300)\n",
    "\n",
    "# train classifier\n",
    "print(\"training...\")\n",
    "SVM_grid.best_estimator_.fit(X_train_w2v, y_train_w2v)\n",
    "print(\"complete.\")\n",
    "# use classifier to predict on test set\n",
    "print(\"predicting...\")\n",
    "SVM_test_preds = SVM_grid.best_estimator_.predict(X_test_w2v)\n",
    "print(\"complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_metrics = {}\n",
    "SVM_default_precision = precision_score(y_test, SVM_test_preds)\n",
    "SVM_default_recall = recall_score(y_test, SVM_test_preds)\n",
    "SVM_default_macro_f1_score = f1_score(y_test, SVM_test_preds, average='macro')\n",
    "\n",
    "#model evaluation\n",
    "print('Model evaluation metrics')\n",
    "print('Precision: {:.3}'.format(SVM_default_precision))\n",
    "print('Recall: {:.3}'.format(SVM_default_recall))\n",
    "print('Macro F1 Score: {:.3}'.format(SVM_default_macro_f1_score))\n",
    "\n",
    "w2v_metrics['Grid SVM'] = {'precision': SVM_default_precision, 'recall': SVM_default_recall, \n",
    "                              'macro_f1': SVM_default_macro_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(SVM_grid, X_test_w2v, y_test_w2v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_grid_LR = LogisticRegression(penalty='l2', dual=False, C=1, class_weight=None, \n",
    "                                solver='lbfgs', random_state=12)\n",
    "\n",
    "# dictionary containing the parameters which will be used for grid search\n",
    "grid_search_params={'penalty': ['l1', 'l2', 'elasticnet'],  \n",
    "              'dual': [True, False], \n",
    "              'C': [1, 10, 30],\n",
    "              'class_weight': [None, 'balanced'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'sag', 'saga', 'liblinear']}\n",
    "\n",
    "# grid search with f1 being the performance metric\n",
    "grid_LR = GridSearchCV(default_grid_LR, grid_search_params, cv=5, scoring='f1_macro', verbose=3)\n",
    "grid_LR.fit(X_train_w2v, y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "print(\"training...\")\n",
    "grid_LR.best_estimator_.fit(X_train_w2v, y_train_w2v)\n",
    "print(\"complete.\")\n",
    "# use classifier to predict on test set\n",
    "print(\"predicting...\")\n",
    "LR_test_preds = grid_LR.best_estimator_.predict(X_test_w2v)\n",
    "print(\"complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_LR_precision = precision_score(y_test_w2v, LR_test_preds)\n",
    "grid_LR_recall = recall_score(y_test_w2v, LR_test_preds)\n",
    "grid_LR_macro_f1_score = f1_score(y_test_w2v, LR_test_preds, average='macro')\n",
    "\n",
    "#model evaluation\n",
    "print('Model evaluation metrics')\n",
    "print('Precision: {:.3}'.format(grid_LR_precision))\n",
    "print('Recall: {:.3}'.format(grid_LR_recall))\n",
    "print('Macro F1 Score: {:.3}'.format(grid_LR_macro_f1_score))\n",
    "\n",
    "w2v_metrics['Grid LR'] = {'precision': grid_LR_precision, 'recall': grid_LR_recall, \n",
    "                            'macro_f1': grid_LR_macro_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_LR, X_test_w2v, y_test_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_NB = GaussianNB()\n",
    "\n",
    "grid_search_params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "grid_NB = GridSearchCV(grid_NB, grid_search_params, cv=5, scoring='f1_macro', verbose=3)\n",
    "\n",
    "grid_NB.fit(X_train_w2v, y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "print(\"training...\")\n",
    "grid_NB.best_estimator_.fit(X_train_w2v, y_train_w2v)\n",
    "print(\"complete.\")\n",
    "# use classifier to predict on test set\n",
    "print(\"predicting...\")\n",
    "NB_test_preds = grid_NB.best_estimator_.predict(X_test_w2v)\n",
    "print(\"complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_NB_precision = precision_score(y_test_w2v, NB_test_preds)\n",
    "grid_NB_recall = recall_score(y_test_w2v, NB_test_preds)\n",
    "grid_NB_macro_f1_score = f1_score(y_test_w2v, NB_test_preds, average='macro')\n",
    "\n",
    "#model evaluation\n",
    "print('Model evaluation metrics')\n",
    "print('Precision: {:.3}'.format(grid_NB_precision))\n",
    "print('Recall: {:.3}'.format(grid_NB_recall))\n",
    "print('Macro F1 Score: {:.3}'.format(grid_NB_macro_f1_score))\n",
    "\n",
    "w2v_metrics['Grid NB'] = {'precision': grid_NB_precision, 'recall': grid_NB_recall, \n",
    "                            'macro_f1': grid_NB_macro_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_NB, X_test_w2v, y_test_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame.from_dict(w2v_metrics, orient='index')\n",
    "results.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Results\\w2v_results\",\n",
    "               index=False)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
