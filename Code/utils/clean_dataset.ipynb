{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\unclean_combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596965466238619648</td>\n",
       "      <td>I just found the *perfect* rental. Why can't m...</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575891807873040384</td>\n",
       "      <td>@wetsprocket every time they \"discover\" anythi...</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595259457828884480</td>\n",
       "      <td>ok time to write code bbl.\\n\\nmaking a new thing.</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572344911002927104</td>\n",
       "      <td>Refined dessert! NOT #MKR</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568132033215475712</td>\n",
       "      <td>@furt1v3ly @ClarkHat One of the best things an...</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0 596965466238619648  I just found the *perfect* rental. Why can't m...   \n",
       "1 575891807873040384  @wetsprocket every time they \"discover\" anythi...   \n",
       "2 595259457828884480  ok time to write code bbl.\\n\\nmaking a new thing.   \n",
       "3 572344911002927104                          Refined dessert! NOT #MKR   \n",
       "4 568132033215475712  @furt1v3ly @ClarkHat One of the best things an...   \n",
       "\n",
       "  Annotation  \n",
       "0    Neither  \n",
       "1    Neither  \n",
       "2    Neither  \n",
       "3    Neither  \n",
       "4    Neither  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example tweet with a link in it:\n",
      " Verification: Yes, this is me. http://t.co/UQ9CEJVuAp\n",
      "\n",
      " remove substrings of the 'text' column that have a http or https link...\n",
      "\n",
      "the tweet text now reads:\n",
      " Verification: Yes, this is me. \n"
     ]
    }
   ],
   "source": [
    "#text column requires some cleaning before the data can be used in a model\n",
    "\n",
    "#1 - removing any links (links to websites / pictures)\n",
    "#twitter has a link shortener where links will begin with http://t.co\n",
    "\n",
    "print(\"example tweet with a link in it:\\n\", df.iloc[123].text)\n",
    "\n",
    "import re\n",
    "print(\"\\n remove substrings of the 'text' column that have a http or https link...\\n\")\n",
    "for i in range(len(df)):\n",
    "    current_text = df.iloc[i].text\n",
    "    text_without_link = re.sub('http://\\S+|https://\\S+', '', current_text)\n",
    "    df['text'] = df['text'].replace(current_text, text_without_link)\n",
    "    \n",
    "print(\"the tweet text now reads:\\n\", df.iloc[123].text)\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_no_links.csv\", \n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example tweet with an @ in it:\n",
      " @Auragasmic &lt;--Hysterical feminazi Level 100 @jtidyman @TheMitch182 @E__Strobel\n",
      "\n",
      " remove substrings of the 'text' column that begin with an @...\n",
      "\n",
      "the tweet text now reads:\n",
      "  &lt;--Hysterical feminazi Level 100   \n",
      "\n",
      "example tweet with an RT in it:\n",
      " RT  Gonna be making a big announcement at the panel I am on about online harassment today :D \n",
      "\n",
      "the tweet text now reads:\n",
      "   Gonna be making a big announcement at the panel I am on about online harassment today :D\n"
     ]
    }
   ],
   "source": [
    "#2 - removing any text that immidiately follows an @ / remove RT\n",
    "#on twitter, text that immidiately follows the @ is known as a tag. this is a way to involve another\n",
    "#user with the tweet, these do not relate to the sentiment of the tweet so they will be removed.\n",
    "\n",
    "print(\"example tweet with an @ in it:\\n\", df.iloc[512].text)\n",
    "print(\"\\n remove substrings of the 'text' column that begin with an @...\\n\")\n",
    "\n",
    "for i in range(len(df)):\n",
    "    current_text = df.iloc[i].text\n",
    "    text_without_at = re.sub('@\\S+', '', current_text)\n",
    "    df['text'] = df['text'].replace(current_text, text_without_at)\n",
    "    \n",
    "print(\"the tweet text now reads:\\n\", df.iloc[512].text)\n",
    "\n",
    "#RT is text that tends to specify a retweet, removing as it doesnt add much to the context\n",
    "print(\"\\nexample tweet with an RT in it:\\n\", df.iloc[9].text, \"\\n\")\n",
    "for i in range(len(df)):\n",
    "    current_text = df.iloc[i].text\n",
    "    text_without_rt = re.sub(r\"\\bRT\\b\", \"\", current_text)\n",
    "    df['text'] = df['text'].replace(current_text, text_without_rt)\n",
    "    \n",
    "print(\"the tweet text now reads:\\n\", df.iloc[9].text)\n",
    "\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_nl_n@.csv\", \n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the last tweet text now reads:\n",
      "  --Hysterical feminazi Level 100    \n",
      "\n",
      "example tweet with some punctuation in it:\n",
      " It's difficult deciding to call out something as being problematic, because that gives it attention and not many people know about it.\n",
      "the tweet text now reads:\n",
      " Its difficult deciding to call out something as being problematic because that gives it attention and not many people know about it\n"
     ]
    }
   ],
   "source": [
    "#3 - punctuation cleaning \n",
    "#some symbol cleaning \n",
    "#change &amp; to and\n",
    "df['text'] = df['text'].str.replace('&amp;', 'and')\n",
    "# remove &lt; (<)\n",
    "df['text'] = df['text'].str.replace('&lt;', '')\n",
    "print(\"the last tweet text now reads:\\n\", df.iloc[512].text, \"\\n\")\n",
    "\n",
    "#remove punctuation\n",
    "print(\"example tweet with some punctuation in it:\\n\", df.iloc[3123].text)\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
    "print(\"the tweet text now reads:\\n\", df.iloc[3123].text)\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_nl_n@_np.csv\", \n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is a datapoint with an empty field\n",
      "id           573180997631537216\n",
      "text                           \n",
      "Annotation              Neither\n",
      "Name: 16, dtype: object \n",
      "\n",
      "Dataset length before empty removal: 6946\n",
      "Dataset length after empty removal: 6836 \n",
      "\n",
      "the datapoint has now been removed and index reformatted\n",
      "\n",
      "id                                           563378742152540160\n",
      "text            And White people who bring up queerness or b...\n",
      "Annotation                                              Neither\n",
      "Name: 16, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#4 - remove tweets which are now empty\n",
    "print(\"here is a datapoint with an empty field\")\n",
    "print(df.iloc[16], \"\\n\")\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "print(\"Dataset length before empty removal:\", len(df))\n",
    "df = df.dropna()\n",
    "\n",
    "#reset the index since we removed some items\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis=1)\n",
    "print(\"Dataset length after empty removal:\", len(df), \"\\n\")\n",
    "print(\"the datapoint has now been removed and index reformatted\\n\")\n",
    "print(df.iloc[16])\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_nl_n@_np_ne.csv\", \n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596965466238619648</td>\n",
       "      <td>i just found the perfect rental why cant my le...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[i, just, found, the, perfect, rental, why, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575891807873040384</td>\n",
       "      <td>every time they discover anything its either ...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[every, time, they, discover, anything, its, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595259457828884480</td>\n",
       "      <td>ok time to write code bbl\\n\\nmaking a new thing</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[ok, time, to, write, code, bbl, making, a, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572344911002927104</td>\n",
       "      <td>refined dessert not mkr</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[refined, dessert, not, mkr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568132033215475712</td>\n",
       "      <td>one of the best things anyone can do to impr...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[one, of, the, best, things, anyone, can, do, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0 596965466238619648  i just found the perfect rental why cant my le...   \n",
       "1 575891807873040384   every time they discover anything its either ...   \n",
       "2 595259457828884480    ok time to write code bbl\\n\\nmaking a new thing   \n",
       "3 572344911002927104                            refined dessert not mkr   \n",
       "4 568132033215475712    one of the best things anyone can do to impr...   \n",
       "\n",
       "  Annotation                                     tokenized_text  \n",
       "0    Neither  [i, just, found, the, perfect, rental, why, ca...  \n",
       "1    Neither  [every, time, they, discover, anything, its, e...  \n",
       "2    Neither  [ok, time, to, write, code, bbl, making, a, ne...  \n",
       "3    Neither                       [refined, dessert, not, mkr]  \n",
       "4    Neither  [one, of, the, best, things, anyone, can, do, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#6 - lowercase / tokenize\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "\n",
    "#tokenize text into a separate column\n",
    "df['tokenized_text'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_nl_n@_np_ne_tokens.csv\", \n",
    "          index=False)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jackc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596965466238619648</td>\n",
       "      <td>i just found the perfect rental why cant my le...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[found, perfect, rental, cant, lease, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575891807873040384</td>\n",
       "      <td>every time they discover anything its either ...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[every, time, discover, anything, either, inco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595259457828884480</td>\n",
       "      <td>ok time to write code bbl\\n\\nmaking a new thing</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[ok, time, write, code, bbl, making, new, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572344911002927104</td>\n",
       "      <td>refined dessert not mkr</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[refined, dessert, mkr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568132033215475712</td>\n",
       "      <td>one of the best things anyone can do to impr...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[one, best, things, anyone, improve, understan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0 596965466238619648  i just found the perfect rental why cant my le...   \n",
       "1 575891807873040384   every time they discover anything its either ...   \n",
       "2 595259457828884480    ok time to write code bbl\\n\\nmaking a new thing   \n",
       "3 572344911002927104                            refined dessert not mkr   \n",
       "4 568132033215475712    one of the best things anyone can do to impr...   \n",
       "\n",
       "  Annotation                                     tokenized_text  \n",
       "0    Neither       [found, perfect, rental, cant, lease, right]  \n",
       "1    Neither  [every, time, discover, anything, either, inco...  \n",
       "2    Neither   [ok, time, write, code, bbl, making, new, thing]  \n",
       "3    Neither                            [refined, dessert, mkr]  \n",
       "4    Neither  [one, best, things, anyone, improve, understan...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 - stopword removal\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_nl_n@_np_ne_tokens_ns.csv\", \n",
    "          index=False)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596965466238619648</td>\n",
       "      <td>i just found the perfect rental why cant my le...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[found, perfect, rental, cant, lease, right]</td>\n",
       "      <td>[found, perfect, rental, cant, lease, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575891807873040384</td>\n",
       "      <td>every time they discover anything its either ...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[every, time, discover, anything, either, inco...</td>\n",
       "      <td>[every, time, discover, anything, either, inco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595259457828884480</td>\n",
       "      <td>ok time to write code bbl\\n\\nmaking a new thing</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[ok, time, write, code, bbl, making, new, thing]</td>\n",
       "      <td>[ok, time, write, code, bbl, making, new, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572344911002927104</td>\n",
       "      <td>refined dessert not mkr</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[refined, dessert, mkr]</td>\n",
       "      <td>[refined, dessert, mkr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568132033215475712</td>\n",
       "      <td>one of the best things anyone can do to impr...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[one, best, things, anyone, improve, understan...</td>\n",
       "      <td>[one, best, thing, anyone, improve, understand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0 596965466238619648  i just found the perfect rental why cant my le...   \n",
       "1 575891807873040384   every time they discover anything its either ...   \n",
       "2 595259457828884480    ok time to write code bbl\\n\\nmaking a new thing   \n",
       "3 572344911002927104                            refined dessert not mkr   \n",
       "4 568132033215475712    one of the best things anyone can do to impr...   \n",
       "\n",
       "  Annotation                                     tokenized_text  \\\n",
       "0    Neither       [found, perfect, rental, cant, lease, right]   \n",
       "1    Neither  [every, time, discover, anything, either, inco...   \n",
       "2    Neither   [ok, time, write, code, bbl, making, new, thing]   \n",
       "3    Neither                            [refined, dessert, mkr]   \n",
       "4    Neither  [one, best, things, anyone, improve, understan...   \n",
       "\n",
       "                                          text_lemma  \n",
       "0       [found, perfect, rental, cant, lease, right]  \n",
       "1  [every, time, discover, anything, either, inco...  \n",
       "2   [ok, time, write, code, bbl, making, new, thing]  \n",
       "3                            [refined, dessert, mkr]  \n",
       "4  [one, best, thing, anyone, improve, understand...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "#lemmatize\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "df['text_lemma'] = df[\"tokenized_text\"].apply(lemmatize_text)\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_nl_n@_np_ne_tokens_ns_lem.csv\", \n",
    "          index=False)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596965466238619648</td>\n",
       "      <td>i just found the perfect rental why cant my le...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[found, perfect, rental, cant, lease, right]</td>\n",
       "      <td>[found, perfect, rental, cant, lease, right]</td>\n",
       "      <td>[i_NN, just_RB, found_VBD, the_DT, perfect_JJ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575891807873040384</td>\n",
       "      <td>every time they discover anything its either ...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[every, time, discover, anything, either, inco...</td>\n",
       "      <td>[every, time, discover, anything, either, inco...</td>\n",
       "      <td>[every_DT, time_NN, they_PRP, discover_VBP, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>595259457828884480</td>\n",
       "      <td>ok time to write code bbl\\n\\nmaking a new thing</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[ok, time, write, code, bbl, making, new, thing]</td>\n",
       "      <td>[ok, time, write, code, bbl, making, new, thing]</td>\n",
       "      <td>[ok_JJ, time_NN, to_TO, write_VB, code_NN, bbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572344911002927104</td>\n",
       "      <td>refined dessert not mkr</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[refined, dessert, mkr]</td>\n",
       "      <td>[refined, dessert, mkr]</td>\n",
       "      <td>[refined_VBN, dessert_NN, not_RB, mkr_VB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568132033215475712</td>\n",
       "      <td>one of the best things anyone can do to impr...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>[one, best, things, anyone, improve, understan...</td>\n",
       "      <td>[one, best, thing, anyone, improve, understand...</td>\n",
       "      <td>[one_CD, of_IN, the_DT, best_JJS, things_NNS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6831</th>\n",
       "      <td>186961697997721984</td>\n",
       "      <td>in case you missed it a homophobes guide for d...</td>\n",
       "      <td>Homophobia</td>\n",
       "      <td>[case, missed, homophobes, guide, dealing, gay...</td>\n",
       "      <td>[case, missed, homophobe, guide, dealing, gay,...</td>\n",
       "      <td>[in_IN, case_NN, you_PRP, missed_VBD, it_PRP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6832</th>\n",
       "      <td>186629008824348992</td>\n",
       "      <td>a homophobes guide for dealing with a gay child</td>\n",
       "      <td>Homophobia</td>\n",
       "      <td>[homophobes, guide, dealing, gay, child]</td>\n",
       "      <td>[homophobe, guide, dealing, gay, child]</td>\n",
       "      <td>[a_DT, homophobes_JJ, guide_NN, for_IN, dealin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6833</th>\n",
       "      <td>185639770825830016</td>\n",
       "      <td>joey mitchell  reads through our 100 real twee...</td>\n",
       "      <td>Homophobia</td>\n",
       "      <td>[joey, mitchell, reads, 100, real, tweets, hom...</td>\n",
       "      <td>[joey, mitchell, read, 100, real, tweet, homop...</td>\n",
       "      <td>[joey_NN, mitchell_NN, reads_VBZ, through_IN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>182386216543600992</td>\n",
       "      <td>why i hate gay people</td>\n",
       "      <td>Homophobia</td>\n",
       "      <td>[hate, gay, people]</td>\n",
       "      <td>[hate, gay, people]</td>\n",
       "      <td>[why_WRB, i_JJ, hate_NN, gay_NN, people_NNS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>178402291844529984</td>\n",
       "      <td>stop making up your own rules do things the wa...</td>\n",
       "      <td>Homophobia</td>\n",
       "      <td>[stop, making, rules, things, way, god, intend...</td>\n",
       "      <td>[stop, making, rule, thing, way, god, intended...</td>\n",
       "      <td>[stop_NN, making_VBG, up_RP, your_PRP, $, own_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6836 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0    596965466238619648  i just found the perfect rental why cant my le...   \n",
       "1    575891807873040384   every time they discover anything its either ...   \n",
       "2    595259457828884480    ok time to write code bbl\\n\\nmaking a new thing   \n",
       "3    572344911002927104                            refined dessert not mkr   \n",
       "4    568132033215475712    one of the best things anyone can do to impr...   \n",
       "...                 ...                                                ...   \n",
       "6831 186961697997721984  in case you missed it a homophobes guide for d...   \n",
       "6832 186629008824348992  a homophobes guide for dealing with a gay child     \n",
       "6833 185639770825830016  joey mitchell  reads through our 100 real twee...   \n",
       "6834 182386216543600992                           why i hate gay people      \n",
       "6835 178402291844529984  stop making up your own rules do things the wa...   \n",
       "\n",
       "      Annotation                                     tokenized_text  \\\n",
       "0        Neither       [found, perfect, rental, cant, lease, right]   \n",
       "1        Neither  [every, time, discover, anything, either, inco...   \n",
       "2        Neither   [ok, time, write, code, bbl, making, new, thing]   \n",
       "3        Neither                            [refined, dessert, mkr]   \n",
       "4        Neither  [one, best, things, anyone, improve, understan...   \n",
       "...          ...                                                ...   \n",
       "6831  Homophobia  [case, missed, homophobes, guide, dealing, gay...   \n",
       "6832  Homophobia           [homophobes, guide, dealing, gay, child]   \n",
       "6833  Homophobia  [joey, mitchell, reads, 100, real, tweets, hom...   \n",
       "6834  Homophobia                                [hate, gay, people]   \n",
       "6835  Homophobia  [stop, making, rules, things, way, god, intend...   \n",
       "\n",
       "                                             text_lemma  \\\n",
       "0          [found, perfect, rental, cant, lease, right]   \n",
       "1     [every, time, discover, anything, either, inco...   \n",
       "2      [ok, time, write, code, bbl, making, new, thing]   \n",
       "3                               [refined, dessert, mkr]   \n",
       "4     [one, best, thing, anyone, improve, understand...   \n",
       "...                                                 ...   \n",
       "6831  [case, missed, homophobe, guide, dealing, gay,...   \n",
       "6832            [homophobe, guide, dealing, gay, child]   \n",
       "6833  [joey, mitchell, read, 100, real, tweet, homop...   \n",
       "6834                                [hate, gay, people]   \n",
       "6835  [stop, making, rule, thing, way, god, intended...   \n",
       "\n",
       "                                               pos_tags  \n",
       "0     [i_NN, just_RB, found_VBD, the_DT, perfect_JJ,...  \n",
       "1     [every_DT, time_NN, they_PRP, discover_VBP, an...  \n",
       "2     [ok_JJ, time_NN, to_TO, write_VB, code_NN, bbl...  \n",
       "3             [refined_VBN, dessert_NN, not_RB, mkr_VB]  \n",
       "4     [one_CD, of_IN, the_DT, best_JJS, things_NNS, ...  \n",
       "...                                                 ...  \n",
       "6831  [in_IN, case_NN, you_PRP, missed_VBD, it_PRP, ...  \n",
       "6832  [a_DT, homophobes_JJ, guide_NN, for_IN, dealin...  \n",
       "6833  [joey_NN, mitchell_NN, reads_VBZ, through_IN, ...  \n",
       "6834       [why_WRB, i_JJ, hate_NN, gay_NN, people_NNS]  \n",
       "6835  [stop_NN, making_VBG, up_RP, your_PRP, $, own_...  \n",
       "\n",
       "[6836 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a column of pos tagged words in each tweet\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "tweets = df.text\n",
    "tweet_tags = []\n",
    "\n",
    "for t in tweets:\n",
    "    tokens = nltk.word_tokenize(t)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    new_text = []\n",
    "    for word in tags:\n",
    "        new_text.append(word[0] + \"_\" + word[1])\n",
    "    tweet_tags.append(new_text)\n",
    "    \n",
    "tagged_tokens = []\n",
    "for tweet in tweet_tags:\n",
    "    sent = ' '.join(tweet)\n",
    "    new_tokens = tokenizer.tokenize(sent)\n",
    "    tagged_tokens.append(new_tokens)\n",
    "    \n",
    "df['pos_tags'] = tagged_tokens\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-5c3cf0e1db0e>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Hate'][i] = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                               570731745752064000\n",
       "text               yes it is legit sweden is one place any livin...\n",
       "Annotation                                                   Sexism\n",
       "tokenized_text    [yes, legit, sweden, one, place, living, thing...\n",
       "text_lemma        [yes, legit, sweden, one, place, living, thing...\n",
       "pos_tags          [yes_NNS, it_PRP, is_VBZ, legit_JJ, sweden_NN,...\n",
       "Hate                                                              1\n",
       "Name: 1000, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finally, add a binary Hate column which we will use for hate/non-hate classification\n",
    "df['Hate'] = 0\n",
    "for i in range(len(df)):\n",
    "    if (df['Annotation'][i] != 'Neither'):\n",
    "        df['Hate'][i] = 1\n",
    "        \n",
    "df.to_csv(r\"C:\\Users\\jackc\\Semester2\\Project\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\clean_dataset.csv\", \n",
    "          index=False)\n",
    "        \n",
    "df.iloc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
