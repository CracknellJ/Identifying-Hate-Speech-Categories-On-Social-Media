{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0             TweetID HateType  \\\n",
      "0           0  572342978255048705   racism   \n",
      "1           1  572341498827522049   racism   \n",
      "2           2  572340476503724032   racism   \n",
      "3           3  572334712804384768   racism   \n",
      "4           4  572332655397629952   racism   \n",
      "\n",
      "                                           TweetText  Hate  \n",
      "0  So Drasko just said he was impressed the girls...     1  \n",
      "1  Drasko they didn't cook half a bird you idiot ...     1  \n",
      "2  Hopefully someone cooks Drasko in the next ep ...     1  \n",
      "3  of course you were born in serbia...you're as ...     1  \n",
      "4  These girls are the equivalent of the irritati...     1  \n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "   Unnamed: 0             TweetID   Expert  \\\n",
      "0           0  574406292736888832  neither   \n",
      "1           1  596820217163948032  neither   \n",
      "2           2  567086711201476608  neither   \n",
      "3           3  563320554682204160  neither   \n",
      "4           4  563879137656307712  neither   \n",
      "\n",
      "                                           TweetText  Hate  \n",
      "0  She's trying to summon a mob, making false all...     0  \n",
      "1  Life is to short to not dress like every day i...     0  \n",
      "2  @techgirlwonder @IdahoEv yup! People should be...     0  \n",
      "3  @Bard_of_peace it helps remembering how many e...     0  \n",
      "4                   @girlziplocked i know that feel.     0  \n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\Jack\\Desktop\\proj\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_part1_unclean.csv')\n",
    "df2 = pd.read_csv(r'C:\\Users\\Jack\\Desktop\\proj\\Identifying-Hate-Speech-Categories-On-Social-Media\\Data\\dataset_part2_unclean.csv')\n",
    "\n",
    "print(df1.head(5))\n",
    "print(\"\")\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(\"\")\n",
    "print(df2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TweetID HateType  \\\n",
      "0  572342978255048705   racism   \n",
      "1  572341498827522049   racism   \n",
      "2  572340476503724032   racism   \n",
      "3  572334712804384768   racism   \n",
      "4  572332655397629952   racism   \n",
      "\n",
      "                                           TweetText  Hate  \n",
      "0  So Drasko just said he was impressed the girls...     1  \n",
      "1  Drasko they didn't cook half a bird you idiot ...     1  \n",
      "2  Hopefully someone cooks Drasko in the next ep ...     1  \n",
      "3  of course you were born in serbia...you're as ...     1  \n",
      "4  These girls are the equivalent of the irritati...     1  \n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "              TweetID   Expert  \\\n",
      "0  574406292736888832  neither   \n",
      "1  596820217163948032  neither   \n",
      "2  567086711201476608  neither   \n",
      "3  563320554682204160  neither   \n",
      "4  563879137656307712  neither   \n",
      "\n",
      "                                           TweetText  Hate  \n",
      "0  She's trying to summon a mob, making false all...     0  \n",
      "1  Life is to short to not dress like every day i...     0  \n",
      "2  @techgirlwonder @IdahoEv yup! People should be...     0  \n",
      "3  @Bard_of_peace it helps remembering how many e...     0  \n",
      "4                   @girlziplocked i know that feel.     0  \n"
     ]
    }
   ],
   "source": [
    "#removing the duplicate index column\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "df2 = df2.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "print(df1.head(5))\n",
    "print(\"\")\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(\"\")\n",
    "print(df2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TweetID HateType  \\\n",
      "0  574406292736888832  neither   \n",
      "1  596820217163948032  neither   \n",
      "2  567086711201476608  neither   \n",
      "3  563320554682204160  neither   \n",
      "4  563879137656307712  neither   \n",
      "\n",
      "                                           TweetText  Hate  \n",
      "0  She's trying to summon a mob, making false all...     0  \n",
      "1  Life is to short to not dress like every day i...     0  \n",
      "2  @techgirlwonder @IdahoEv yup! People should be...     0  \n",
      "3  @Bard_of_peace it helps remembering how many e...     0  \n",
      "4                   @girlziplocked i know that feel.     0  \n"
     ]
    }
   ],
   "source": [
    "#renaming the expert column in df2 to 'HateType' - preparation to merge both the dataframes\n",
    "df2 = df2.rename(columns={\"Expert\": \"HateType\"})\n",
    "print(df2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 size:  1589\n",
      "df2 size:  1580\n",
      "combined dataset size:  3169\n"
     ]
    }
   ],
   "source": [
    "#combine both the dataframes into one dataset\n",
    "print(\"df1 size: \", len(df1))\n",
    "print(\"df2 size: \", len(df2))\n",
    "frames = [df1, df2]\n",
    "dataset = pd.concat(frames)\n",
    "print(\"combined dataset size: \", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 TweetID HateType  \\\n",
      "3     563320554682204160  neither   \n",
      "4     563879137656307712  neither   \n",
      "19    564581360279384064  neither   \n",
      "39    562740201869824001  neither   \n",
      "42    563867096048619520  neither   \n",
      "...                  ...      ...   \n",
      "1534  563426173036658688  neither   \n",
      "1535  563908401327915009  neither   \n",
      "1548  563450162324832257  neither   \n",
      "1557  564592237305004032  neither   \n",
      "1571  563763995648081920  neither   \n",
      "\n",
      "                                              TweetText  Hate  \n",
      "3     @Bard_of_peace it helps remembering how many e...     0  \n",
      "4                      @girlziplocked i know that feel.     0  \n",
      "19    @ctmf they are already setting up  bots to twe...     0  \n",
      "39             @Zython86 fuck errything about brietbart     0  \n",
      "42    It's cool. I'm sure @wadhwa is going to say NP...     0  \n",
      "...                                                 ...   ...  \n",
      "1534                   @jasonschreier @vogon well done.     0  \n",
      "1535              My new mascot. http://t.co/AugbPO2t3v     0  \n",
      "1548  RT @a_man_in_black: @freebsdgirl and at 1:46:0...     0  \n",
      "1557  or so I can direct parents there around xmas t...     0  \n",
      "1571  Someone get me an ETA on when the storm is goi...     0  \n",
      "\n",
      "[206 rows x 4 columns]\n",
      "combined dataset size without duplicate tweets:  2963\n"
     ]
    }
   ],
   "source": [
    "#look for and remove any duplicate tweets\n",
    "\n",
    "print(dataset[dataset.duplicated(['TweetID'], keep='first')])\n",
    "\n",
    "dataset_no_dupes = dataset.drop_duplicates(subset=['TweetID'], keep='first')\n",
    "\n",
    "print(\"combined dataset size without duplicate tweets: \", len(dataset_no_dupes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none      2096\n",
      "sexism     844\n",
      "racism      18\n",
      "both         5\n",
      "Name: HateType, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "#when the datasets were combined, we got a disparity in the hatetype column.\n",
    "#we will set any tweet which contains no hate speech to 'none'\n",
    "dataset_no_dupes[\"HateType\"].replace({\"neither\": \"none\"}, inplace=True)\n",
    "        \n",
    "print(dataset_no_dupes['HateType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_no_dupes.to_csv(\"dataset_no_dupes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
